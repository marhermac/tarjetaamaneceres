# ğŸ§¹ Data Cleaning Challenge: E-commerce Inventory

Este proyecto demuestra un proceso completo de **limpieza, normalizaciÃ³n y transformaciÃ³n de datos** sobre un dataset simulado de **5.000 registros** y **mÃ¡s de 100 columnas**, utilizando **Python y Pandas**.

El objetivo es transformar datos crudos e inconsistentes en un dataset confiable, listo para anÃ¡lisis estadÃ­stico y visualizaciÃ³n en herramientas como **Power BI** o **Tableau**.

---

## ğŸ“Œ Escenario

Una empresa de Retail recolectÃ³ informaciÃ³n de inventario desde mÃºltiples sucursales en **Argentina** y **Estados Unidos**.  
Debido a la carga manual, los datos presentaban errores crÃ­ticos que impedÃ­an cualquier anÃ¡lisis confiable.

---

## ğŸ› ï¸ Problemas Detectados y Resueltos

El script de limpieza aborda los siguientes problemas reales:

- **EstandarizaciÃ³n geogrÃ¡fica**  
  UnificaciÃ³n de variantes como `arg`, `arg.`, `EE.UU`, `usa` en nombres oficiales normalizados.

- **Limpieza de precios**  
  ConversiÃ³n de strings con sÃ­mbolos y separadores inconsistentes (ej: `$ 1.200,50`) a valores numÃ©ricos `float`.

- **NormalizaciÃ³n de fechas**  
  ConversiÃ³n de mÃºltiples formatos (`DD/MM/YY`, `YYYY-MM-DD`, `May 1st`) al estÃ¡ndar ISO.

- **Tratamiento de nulos y duplicados**  
  ImputaciÃ³n de valores faltantes en categorÃ­as y eliminaciÃ³n de duplicados tras normalizar IDs.

---

## ğŸ“Š TecnologÃ­as Utilizadas

- **Python 3.x**
- **Pandas** â€“ procesamiento y limpieza de datos
- **NumPy** â€“ manejo de valores nulos
- **Regular Expressions (Regex)** â€“ limpieza y normalizaciÃ³n de texto

---

## ğŸ“ Estructura del Proyecto

- `dirty_data_challenge.csv` â†’ dataset original con errores
- `limpieza.py` â†’ script de limpieza y transformaciÃ³n
- `clean_data_final.csv` â†’ dataset final listo para anÃ¡lisis
- `imagenes/` â†’ capturas del antes y despuÃ©s del proceso

## ğŸ§  Script principal: `limpieza.py`

El archivo `limpieza.py` contiene la lÃ³gica completa del proceso de limpieza de datos, incluyendo:

- NormalizaciÃ³n de valores geogrÃ¡ficos mediante diccionarios de mapeo  
- ConversiÃ³n de precios desde texto a valores numÃ©ricos  
- UnificaciÃ³n de formatos de fecha heterogÃ©neos  
- Limpieza de identificadores y categorÃ­as  
- EliminaciÃ³n de duplicados y validaciÃ³n final del dataset  

El script fue diseÃ±ado para ser **claro, reproducible y fÃ¡cilmente adaptable** a otros datasets similares.

---

## ğŸš€ CÃ³mo ejecutarlo

1. Clonar el repositorio  
   ```bash
   git clone https://github.com/marhermac/mariomaciel.git
2. Instalar dependencias
   ```bash
   pip install pandas numpy
3. Ejecutar el script
   ```bash
   python limpieza.py
 
ğŸ“Š Resultado del proceso de limpieza

Dataset original (datos sucios)
<p align="center"> <img src="imagenes/dirty_data_before.png" width="650"> </p>
Dataset final (datos limpios)
<p align="center"> <img src="imagenes/clear_data_after.png" width="650"> </p>




---

